{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ],
   "metadata": {
    "id": "xVZYU40LyE7x",
    "ExecuteTime": {
     "end_time": "2024-04-01T06:47:36.808369Z",
     "start_time": "2024-04-01T06:47:36.309373Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_df = pd.read_csv('../datasets/test_essays.csv')\n",
    "submission_df = pd.read_csv('../datasets/sample_submission.csv')\n",
    "train_df = pd.read_csv(\"../datasets/train_v2_drcat_02.csv\")\n",
    "kf_df = pd.read_csv('../datasets/kf_df.csv')"
   ],
   "metadata": {
    "id": "fNkajketyJIk",
    "ExecuteTime": {
     "end_time": "2024-04-01T06:47:38.339804Z",
     "start_time": "2024-04-01T06:47:36.809371Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "kf_df = kf_df.rename(columns={'prompt_title': 'prompt_name'})\n",
    "kf_df['label'] = 1\n",
    "kf_df['source'] = 'kf'\n",
    "kf_df['RDizzl3_seven'] = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:47:38.355819Z",
     "start_time": "2024-04-01T06:47:38.340803Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, kf_df[train_df.columns].sample(30000, random_state=42)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:47:38.387835Z",
     "start_time": "2024-04-01T06:47:38.357819Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    text  label  \\\n0      Phones\\n\\nModern humans today are always on th...      0   \n1      This essay will explain if drivers should or s...      0   \n2      Driving while the use of cellular devices\\n\\nT...      0   \n3      Phones & Driving\\n\\nDrivers should not be able...      0   \n4      Cell Phone Operation While Driving\\n\\nThe abil...      0   \n...                                                  ...    ...   \n29644  The article discusses the concept of domestica...      1   \n42301  Background noise can make it difficult to hear...      1   \n46584  Long ago, there were many different species of...      1   \n52305  Chemotherapy drugs are used to treat cancer, b...      1   \n25798  Plant-parasitic nematodes are tiny roundworms ...      1   \n\n                                             prompt_name           source  \\\n0                                     Phones and driving  persuade_corpus   \n1                                     Phones and driving  persuade_corpus   \n2                                     Phones and driving  persuade_corpus   \n3                                     Phones and driving  persuade_corpus   \n4                                     Phones and driving  persuade_corpus   \n...                                                  ...              ...   \n29644               Are Humans More Like Wolves or Dogs?               kf   \n42301  I Canâ€™t Hear Myself Think! How the Brain Deals...               kf   \n46584  What Would the Child of a Human and a Neandert...               kf   \n52305     Getting to the Bottom of Cancer Treatment Pain               kf   \n25798  Plant-Eating Nematodes and the Key to Fighting...               kf   \n\n       RDizzl3_seven  \n0              False  \n1              False  \n2              False  \n3              False  \n4              False  \n...              ...  \n29644          False  \n42301          False  \n46584          False  \n52305          False  \n25798          False  \n\n[74868 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>prompt_name</th>\n      <th>source</th>\n      <th>RDizzl3_seven</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Phones\\n\\nModern humans today are always on th...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This essay will explain if drivers should or s...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Driving while the use of cellular devices\\n\\nT...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29644</th>\n      <td>The article discusses the concept of domestica...</td>\n      <td>1</td>\n      <td>Are Humans More Like Wolves or Dogs?</td>\n      <td>kf</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>42301</th>\n      <td>Background noise can make it difficult to hear...</td>\n      <td>1</td>\n      <td>I Canâ€™t Hear Myself Think! How the Brain Deals...</td>\n      <td>kf</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>46584</th>\n      <td>Long ago, there were many different species of...</td>\n      <td>1</td>\n      <td>What Would the Child of a Human and a Neandert...</td>\n      <td>kf</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>52305</th>\n      <td>Chemotherapy drugs are used to treat cancer, b...</td>\n      <td>1</td>\n      <td>Getting to the Bottom of Cancer Treatment Pain</td>\n      <td>kf</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>25798</th>\n      <td>Plant-parasitic nematodes are tiny roundworms ...</td>\n      <td>1</td>\n      <td>Plant-Eating Nematodes and the Key to Fighting...</td>\n      <td>kf</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>74868 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:47:38.403839Z",
     "start_time": "2024-04-01T06:47:38.388835Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1. Text Preprocessing"
   ],
   "metadata": {
    "id": "_xSnuhLuyQ9Q"
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_df[\"words_count\"] = train_df[\"text\"].apply(lambda x: len(x.split(\" \")))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:47:39.199773Z",
     "start_time": "2024-04-01T06:47:38.404836Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    text  label  \\\n0      Phones\\n\\nModern humans today are always on th...      0   \n1      This essay will explain if drivers should or s...      0   \n2      Driving while the use of cellular devices\\n\\nT...      0   \n3      Phones & Driving\\n\\nDrivers should not be able...      0   \n4      Cell Phone Operation While Driving\\n\\nThe abil...      0   \n...                                                  ...    ...   \n29644  The article discusses the concept of domestica...      1   \n42301  Background noise can make it difficult to hear...      1   \n46584  Long ago, there were many different species of...      1   \n52305  Chemotherapy drugs are used to treat cancer, b...      1   \n25798  Plant-parasitic nematodes are tiny roundworms ...      1   \n\n                                             prompt_name           source  \\\n0                                     Phones and driving  persuade_corpus   \n1                                     Phones and driving  persuade_corpus   \n2                                     Phones and driving  persuade_corpus   \n3                                     Phones and driving  persuade_corpus   \n4                                     Phones and driving  persuade_corpus   \n...                                                  ...              ...   \n29644               Are Humans More Like Wolves or Dogs?               kf   \n42301  I Canâ€™t Hear Myself Think! How the Brain Deals...               kf   \n46584  What Would the Child of a Human and a Neandert...               kf   \n52305     Getting to the Bottom of Cancer Treatment Pain               kf   \n25798  Plant-Eating Nematodes and the Key to Fighting...               kf   \n\n       RDizzl3_seven  words_count  \n0              False          378  \n1              False          432  \n2              False          179  \n3              False          221  \n4              False          334  \n...              ...          ...  \n29644          False          194  \n42301          False          199  \n46584          False          123  \n52305          False          241  \n25798          False          298  \n\n[74868 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>prompt_name</th>\n      <th>source</th>\n      <th>RDizzl3_seven</th>\n      <th>words_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Phones\\n\\nModern humans today are always on th...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n      <td>378</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This essay will explain if drivers should or s...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n      <td>432</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Driving while the use of cellular devices\\n\\nT...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n      <td>179</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n      <td>221</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n      <td>334</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29644</th>\n      <td>The article discusses the concept of domestica...</td>\n      <td>1</td>\n      <td>Are Humans More Like Wolves or Dogs?</td>\n      <td>kf</td>\n      <td>False</td>\n      <td>194</td>\n    </tr>\n    <tr>\n      <th>42301</th>\n      <td>Background noise can make it difficult to hear...</td>\n      <td>1</td>\n      <td>I Canâ€™t Hear Myself Think! How the Brain Deals...</td>\n      <td>kf</td>\n      <td>False</td>\n      <td>199</td>\n    </tr>\n    <tr>\n      <th>46584</th>\n      <td>Long ago, there were many different species of...</td>\n      <td>1</td>\n      <td>What Would the Child of a Human and a Neandert...</td>\n      <td>kf</td>\n      <td>False</td>\n      <td>123</td>\n    </tr>\n    <tr>\n      <th>52305</th>\n      <td>Chemotherapy drugs are used to treat cancer, b...</td>\n      <td>1</td>\n      <td>Getting to the Bottom of Cancer Treatment Pain</td>\n      <td>kf</td>\n      <td>False</td>\n      <td>241</td>\n    </tr>\n    <tr>\n      <th>25798</th>\n      <td>Plant-parasitic nematodes are tiny roundworms ...</td>\n      <td>1</td>\n      <td>Plant-Eating Nematodes and the Key to Fighting...</td>\n      <td>kf</td>\n      <td>False</td>\n      <td>298</td>\n    </tr>\n  </tbody>\n</table>\n<p>74868 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:47:39.215776Z",
     "start_time": "2024-04-01T06:47:39.200774Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "424.90153812429213"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.query(\"label == 0\")[\"words_count\"].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:47:39.231774Z",
     "start_time": "2024-04-01T06:47:39.216774Z"
    }
   },
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "228.13765079899784"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.query(\"label == 1\")[\"words_count\"].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:47:39.247774Z",
     "start_time": "2024-04-01T06:47:39.232774Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_df[\"generated\"] = train_df[\"label\"].apply(lambda x: 1.0 if x == 1 else 0.0)\n",
    "train_df[\"human\"] = train_df[\"label\"].apply(lambda x: 1.0 if x == 0 else 0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:47:39.279774Z",
     "start_time": "2024-04-01T06:47:39.248776Z"
    }
   },
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2. Modeling"
   ],
   "metadata": {
    "id": "Tt0e5xkSwRJY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(train_df, test_size=0.30, random_state=42, shuffle=True, stratify=train_df[\"label\"])"
   ],
   "metadata": {
    "id": "pZVRw8Si2o4L",
    "ExecuteTime": {
     "end_time": "2024-04-01T06:47:40.031777Z",
     "start_time": "2024-04-01T06:47:39.280775Z"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train.groupby(\"label\").count()"
   ],
   "metadata": {
    "id": "4E-gxq733qI1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "outputId": "b020c59e-1a79-40c7-98ba-b122b85dc518",
    "ExecuteTime": {
     "end_time": "2024-04-01T06:47:40.063774Z",
     "start_time": "2024-04-01T06:47:40.033776Z"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "        text  prompt_name  source  RDizzl3_seven  words_count  generated  \\\nlabel                                                                      \n0      19159        19159   19159          19159        19159      19159   \n1      33248        33248   33248          33248        33248      33248   \n\n       human  \nlabel         \n0      19159  \n1      33248  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>prompt_name</th>\n      <th>source</th>\n      <th>RDizzl3_seven</th>\n      <th>words_count</th>\n      <th>generated</th>\n      <th>human</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19159</td>\n      <td>19159</td>\n      <td>19159</td>\n      <td>19159</td>\n      <td>19159</td>\n      <td>19159</td>\n      <td>19159</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>33248</td>\n      <td>33248</td>\n      <td>33248</td>\n      <td>33248</td>\n      <td>33248</td>\n      <td>33248</td>\n      <td>33248</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test.groupby(\"label\").count()"
   ],
   "metadata": {
    "id": "LulDxMfC3rQy",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "outputId": "f2e1bb6f-a0cc-410d-cb9d-b1abfdb43574",
    "ExecuteTime": {
     "end_time": "2024-04-01T06:47:40.079774Z",
     "start_time": "2024-04-01T06:47:40.064775Z"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "        text  prompt_name  source  RDizzl3_seven  words_count  generated  \\\nlabel                                                                      \n0       8212         8212    8212           8212         8212       8212   \n1      14249        14249   14249          14249        14249      14249   \n\n       human  \nlabel         \n0       8212  \n1      14249  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>prompt_name</th>\n      <th>source</th>\n      <th>RDizzl3_seven</th>\n      <th>words_count</th>\n      <th>generated</th>\n      <th>human</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8212</td>\n      <td>8212</td>\n      <td>8212</td>\n      <td>8212</td>\n      <td>8212</td>\n      <td>8212</td>\n      <td>8212</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14249</td>\n      <td>14249</td>\n      <td>14249</td>\n      <td>14249</td>\n      <td>14249</td>\n      <td>14249</td>\n      <td>14249</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\")\n",
    "test.to_csv(\"test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:47:42.342281Z",
     "start_time": "2024-04-01T06:47:40.080774Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training"
   ],
   "metadata": {
    "id": "VLdplTrt38ZP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "classification_trainer = ClassificationTrainer(\n",
    "    pretrained_transformer_name='cointegrated/rubert-tiny2',\n",
    "    dataset_dct={'train':'train.csv', 'test': 'test.csv'},\n",
    "    warmup_steps=100,\n",
    "    num_train_epochs=3\n",
    ")\n",
    "\n",
    "classification_trainer.trainer.train()"
   ],
   "metadata": {
    "id": "NpII9xBoESF-",
    "ExecuteTime": {
     "start_time": "2024-04-01T06:47:51.772283Z"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gasoline stored in the fuel tank of a vehicle can escape from the vehicle and pollute the environment, even when the vehicle is not running. This occurs because gasoline is volatile and can change from liquid to gas, which can pass into the air. Evaporated gasoline escaping from fuel tanks is a significant source of environmental pollution with volatile organic compounds (VOCs), which can harm the environment and human health. To prevent this leakage of gasoline, modern vehicles are equipped with a canister packed with particles of activated carbon, which captures the gasoline molecules in a maze of carbon molecules. Activated carbon is a charcoal material widely used for the purification of drinking water and natural gas. The adsorption of evaporated gasoline on activated carbon can be compared to the Labyrinth of the Minotaur. The labyrinth passages must be cleaned so that they can adsorb new VOCs the next day. The vehicleâ€™s engine acts as the Minotaur, by feeding on the VOCs. The next time the vehicle is started, air is passed through the canister to separate VOCs from the walls of the activated carbon passages. This process is called desorption, which means unsticking the molecules that are adsorbed to the passages. These desorbed molecules are then burned in the engine. To further improve the adsorption capacity of activated carbon, a waste product called agave bagasse is processed to create a new labyrinth. The addition of carbon nanotubes to the biochar passages increases the capacity of biochar to adsorb VOCs. The production of carbon labyrinths from agave bagasse shows how a waste material can be of interest to the automotive industry and possibly other industries. The adsorption process is also being used to remove pollutants such as arsenic and fluoride from drinking water in countries where these contaminants are a problem.\n",
      "[1. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type distilbert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.word_embeddings.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'transformer.layer.0.attention.k_lin.bias', 'transformer.layer.0.attention.k_lin.weight', 'transformer.layer.0.attention.out_lin.bias', 'transformer.layer.0.attention.out_lin.weight', 'transformer.layer.0.attention.q_lin.bias', 'transformer.layer.0.attention.q_lin.weight', 'transformer.layer.0.attention.v_lin.bias', 'transformer.layer.0.attention.v_lin.weight', 'transformer.layer.0.ffn.lin1.bias', 'transformer.layer.0.ffn.lin1.weight', 'transformer.layer.0.ffn.lin2.bias', 'transformer.layer.0.ffn.lin2.weight', 'transformer.layer.0.output_layer_norm.bias', 'transformer.layer.0.output_layer_norm.weight', 'transformer.layer.0.sa_layer_norm.bias', 'transformer.layer.0.sa_layer_norm.weight', 'transformer.layer.1.attention.k_lin.bias', 'transformer.layer.1.attention.k_lin.weight', 'transformer.layer.1.attention.out_lin.bias', 'transformer.layer.1.attention.out_lin.weight', 'transformer.layer.1.attention.q_lin.bias', 'transformer.layer.1.attention.q_lin.weight', 'transformer.layer.1.attention.v_lin.bias', 'transformer.layer.1.attention.v_lin.weight', 'transformer.layer.1.ffn.lin1.bias', 'transformer.layer.1.ffn.lin1.weight', 'transformer.layer.1.ffn.lin2.bias', 'transformer.layer.1.ffn.lin2.weight', 'transformer.layer.1.output_layer_norm.bias', 'transformer.layer.1.output_layer_norm.weight', 'transformer.layer.1.sa_layer_norm.bias', 'transformer.layer.1.sa_layer_norm.weight', 'transformer.layer.2.attention.k_lin.bias', 'transformer.layer.2.attention.k_lin.weight', 'transformer.layer.2.attention.out_lin.bias', 'transformer.layer.2.attention.out_lin.weight', 'transformer.layer.2.attention.q_lin.bias', 'transformer.layer.2.attention.q_lin.weight', 'transformer.layer.2.attention.v_lin.bias', 'transformer.layer.2.attention.v_lin.weight', 'transformer.layer.2.ffn.lin1.bias', 'transformer.layer.2.ffn.lin1.weight', 'transformer.layer.2.ffn.lin2.bias', 'transformer.layer.2.ffn.lin2.weight', 'transformer.layer.2.output_layer_norm.bias', 'transformer.layer.2.output_layer_norm.weight', 'transformer.layer.2.sa_layer_norm.bias', 'transformer.layer.2.sa_layer_norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\vitya\\AppData\\Local\\Temp\\ipykernel_3564\\1032734142.py:119: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  self.metric = {metric:load_metric(metric) for metric in ['f1', 'precision', 'recall', 'accuracy']}\n",
      "C:\\Users\\vitya\\PycharmProjects\\DetectAIText\\.venv\\lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vitya\\PycharmProjects\\DetectAIText\\.venv\\lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for precision contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/precision/precision.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vitya\\PycharmProjects\\DetectAIText\\.venv\\lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for recall contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/recall/recall.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vitya\\PycharmProjects\\DetectAIText\\.venv\\lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vitya\\PycharmProjects\\DetectAIText\\.venv\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='62' max='17688' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   62/17688 01:07 < 5:30:31, 0.89 it/s, Epoch 0.01/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "metrics = classification_trainer.trainer.evaluate()\n",
    "\n",
    "classification_trainer.trainer.log_metrics(\"after_train_eval\", metrics)\n",
    "classification_trainer.trainer.save_metrics(\"after_train_eval\",\n",
    "                                            metrics)\n",
    "\n"
   ],
   "metadata": {
    "id": "C4eAVO2l4LOZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_metric\n",
    "from transformers import EvalPrediction\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LABELS = ['generated', 'human']\n",
    "id2label = {idx:label for idx, label in enumerate(LABELS)}\n",
    "label2id = {label:idx for idx, label in enumerate(LABELS)}\n",
    "\n",
    "def read_csv_binary(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    texts = data['text'].tolist()\n",
    "    labels = data[LABELS].values\n",
    "\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "            'roc_auc': roc_auc,\n",
    "            'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "class LLMDDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            key: torch.tensor(val[idx])\n",
    "            for key, val in self.encodings.items()\n",
    "        }\n",
    "\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "class ClassificationTrainer():\n",
    "    def __init__(self,\n",
    "                 pretrained_transformer_name='distilbert-base-cased',\n",
    "                 dataset_dct={'train':'train.csv', 'test':'test.csv', 'val':'val.csv'},\n",
    "                 warmup_steps=500,\n",
    "                 num_train_epochs=3):\n",
    "\n",
    "\n",
    "        max_samples = {\n",
    "            'train': 100000,\n",
    "            'val': 100000,\n",
    "            'test': 100000,\n",
    "        }\n",
    "\n",
    "        train_texts, train_labels = read_csv_binary(dataset_dct['train'])\n",
    "\n",
    "        if 'test' not in dataset_dct:\n",
    "            train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "                train_texts, train_labels, test_size=.1)\n",
    "        else:\n",
    "            test_texts, test_labels = read_csv_binary(dataset_dct['test'])\n",
    "\n",
    "        if 'val' not in dataset_dct:\n",
    "            train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "                train_texts, train_labels, test_size=.1)\n",
    "        else:\n",
    "            val_texts, val_labels = read_csv_binary(dataset_dct['val'])\n",
    "\n",
    "        train_texts = train_texts[:max_samples['train']]\n",
    "        val_texts = val_texts[:max_samples['val']]\n",
    "        test_texts = test_texts[:max_samples['test']]\n",
    "\n",
    "        train_labels = train_labels[:max_samples['train']]\n",
    "        val_labels = val_labels[:max_samples['val']]\n",
    "        test_labels = test_labels[:max_samples['test']]\n",
    "\n",
    "        print(train_texts[0])\n",
    "        print(train_labels[0])\n",
    "\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(\n",
    "                pretrained_transformer_name)\n",
    "\n",
    "#Ð¿Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ Ð¿Ð¾ Ð¿Ð°Ñ€Ð°Ð¼ÐºÐµÑ‚Ñ€Ð°Ð¼\n",
    "        train_encodings = self.tokenizer(train_texts, truncation=True, max_length=256, padding=True)\n",
    "        val_encodings = self.tokenizer(val_texts, truncation=True, max_length=256, padding=True)\n",
    "        test_encodings = self.tokenizer(test_texts, truncation=True, max_length=256, padding=True)\n",
    "\n",
    "        self.train_dataset = LLMDDataset(train_encodings, train_labels)\n",
    "        self.val_dataset = LLMDDataset(val_encodings, val_labels)\n",
    "        self.test_dataset = LLMDDataset(test_encodings, test_labels)\n",
    "\n",
    "        self.model = DistilBertForSequenceClassification.from_pretrained(\n",
    "                pretrained_transformer_name, num_labels=len(LABELS), problem_type=\"multi_label_classification\",  id2label=id2label, label2id=label2id)\n",
    "\n",
    "        self.metric = {metric:load_metric(metric) for metric in ['f1', 'precision', 'recall', 'accuracy']}\n",
    "\n",
    "        self.training_args = TrainingArguments(\n",
    "            output_dir='./results',  # output directory\n",
    "            num_train_epochs=num_train_epochs, # total number of training epochs\n",
    "            per_device_train_batch_size=\n",
    "            8,  # batch size per device during training\n",
    "            per_device_eval_batch_size=8,  # batch size for evaluation\n",
    "            warmup_steps=\n",
    "            warmup_steps,  # number of warmup steps for learning rate scheduler\n",
    "            weight_decay=0.01,  # strength of weight decay\n",
    "            logging_dir='./logs',  # directory for storing logs\n",
    "            logging_strategy='epoch',\n",
    "            evaluation_strategy='epoch',\n",
    "            save_strategy='epoch',\n",
    "            save_total_limit = 3,\n",
    "        )\n",
    "\n",
    "        self.trainer = Trainer(\n",
    "            model=self.\n",
    "            model,  # the instantiated ðŸ¤— Transformers model to be trained\n",
    "            args=self.training_args,  # training arguments, defined above\n",
    "            train_dataset=self.train_dataset,  # training dataset\n",
    "            eval_dataset=self.val_dataset,  # evaluation dataset\n",
    "            compute_metrics=self.compute_metrics,\n",
    "        )\n",
    "\n",
    "\n",
    "    def compute_metrics(self, p: EvalPrediction):\n",
    "        preds = p.predictions[0] if isinstance(p.predictions,\n",
    "                tuple) else p.predictions\n",
    "        result = multi_label_metrics(\n",
    "            predictions=preds,\n",
    "            labels=p.label_ids)\n",
    "        return result\n",
    "\n",
    "\n",
    "    def inference(self, predict_dataset=None):\n",
    "        if predict_dataset is None:\n",
    "            predict_dataset = self.test_dataset\n",
    "        predictions = self.trainer.predict(predict_dataset, metric_key_prefix=\"predict\").predictions\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "        return predictions"
   ],
   "metadata": {
    "id": "1DnKMoEN33xH",
    "ExecuteTime": {
     "end_time": "2024-04-01T06:47:51.771282Z",
     "start_time": "2024-04-01T06:47:42.343284Z"
    }
   },
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "text = 'Ð’ÑÐµÐ¼ Ð¿Ñ€Ð¸Ð²ÐµÑ‚!'\n",
    "\n",
    "\n",
    "\n",
    "encoding = classification_trainer.tokenizer(text, return_tensorse='pt')\n",
    "encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n",
    "\n",
    "outputs = trainer.model(**encoding)\n",
    "\n",
    "\n",
    "logits = outputs.logits"
   ],
   "metadata": {
    "id": "jL4H5kmkEqOt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# apply sigmoid + threshold\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(logits.squeeze().cpu())\n",
    "predictions = np.zeros(probs.shape)\n",
    "predictions[np.where(probs >= 0.5)] = 1\n",
    "# turn predicted id's into actual label names\n",
    "predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n",
    "print(predicted_labels)"
   ],
   "metadata": {
    "id": "0NqVubcgFA5G"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def inference(trainer, predict_dataset=None):\n",
    "    if predict_dataset is None:\n",
    "        predict_dataset = trainer.test_dataset\n",
    "    predictions = trainer.trainer.predict(predict_dataset, metric_key_prefix=\"predict\").predictions\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return predictions"
   ],
   "metadata": {
    "id": "Co8xa_Wj4flC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "preds = inference(classification_trainer)\n",
    "test[\"pred_label\"] = [id2label[x] for x in preds]"
   ],
   "metadata": {
    "id": "zYFgJFaHHqoW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "results = test[[\"text\", \"label\", \"pred_label\"]]"
   ],
   "metadata": {
    "id": "q0e6G86LH69N"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results"
   ],
   "metadata": {
    "id": "UVXYO9huIu4Z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "LABELS"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "teSmeFazJG66",
    "outputId": "8c0ac61f-8456-4bbc-b07e-9a13abccd716"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['reminder', 'famil', 'condition', 'basis', 'preambs', 'requests', 'inf_task']"
      ]
     },
     "metadata": {},
     "execution_count": 187
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "results[results[\"label\"] == \"basis\"].sample(100).to_excel(\"model_preds_test_basis.xlsx\")"
   ],
   "metadata": {
    "id": "8Hom_BVFIj1z"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "results[results[\"label\"] == \"reminder\"].sample(100).to_excel(\"model_preds_test_reminder.xlsx\")"
   ],
   "metadata": {
    "id": "rwHYiC6mH0k0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "results[results[\"label\"] == \"famil\"].sample(100).to_excel(\"model_preds_test_famil.xlsx\")"
   ],
   "metadata": {
    "id": "0e8Jf0a5JLL7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "results[results[\"label\"] == \"condition\"].sample(100).to_excel(\"model_preds_test_condition.xlsx\")"
   ],
   "metadata": {
    "id": "u-67OODlJQyu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "results[results[\"label\"] == \"preambs\"].sample(100).to_excel(\"model_preds_test_preambs.xlsx\")"
   ],
   "metadata": {
    "id": "pf_CszuPJUa4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "results[results[\"label\"] == \"requests\"].to_excel(\"model_preds_test_requests.xlsx\")"
   ],
   "metadata": {
    "id": "AVSy9KctJX3S"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "results[results[\"label\"] == \"inf_task\"].sample(100).to_excel(\"model_preds_test_inf_task.xlsx\")"
   ],
   "metadata": {
    "id": "dLCs5Q3LJaZ5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "results[results[\"label\"] == \"requests\"]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "Tv-5gUHlJhHc",
    "outputId": "08d79e36-b4e5-42ea-93ed-1805e6cf486b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, label, pred_label]\n",
       "Index: []"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-d019ec99-10df-4dc6-b760-de164d7b985b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d019ec99-10df-4dc6-b760-de164d7b985b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d019ec99-10df-4dc6-b760-de164d7b985b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d019ec99-10df-4dc6-b760-de164d7b985b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 195
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save Trained Model"
   ],
   "metadata": {
    "id": "XsVIc285rVMe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!cp -r /content/results $DATA_PATH_CLOUD"
   ],
   "metadata": {
    "id": "msJA-9OrLUJ4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "oW-phVcUrb99"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
